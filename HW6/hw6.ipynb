{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Perfect. They do exactly what I need them to do. I will keep them for a long time', 'positive'], ['Excellent product and a much better quality than the one you get at Walmart for $50', 'positive'], ['A little pricey for what it is', 'negative'], ['sheds all over, would not buy it ever again', 'negative'], [\"service was great, can't wait to try it out!Very good quality\", 'positive'], ['bottom will not stay on. zero customer service  do not buy', 'negative'], ['Does not do a very good job', 'negative'], ['difficult to use', 'negative'], ['I am happy with my purchase', 'positive'], ['so poor on quality', 'negative'], ['it was broken and the glass is  cracked bad', 'negative'], ['Only negative is the shape of the container', 'negative'], ['Worst product ever', 'negative'], ['Works very well', 'positive'], ['Perfect! this bag is well made', 'positive'], ['heaply made, poor quality', 'negative'], ['Item as advertised, fast shipping', 'positive'], ['arrived on time', 'positive'], ['This is a must have for anyone', 'positive'], ['Awesome bag', 'positive'], ['The mask was a very poor fit', 'negative'], [\"I've really enjoyed using this\", 'positive'], ['Unfortunately, there were no batteries', 'negative'], ['These are adorable!', 'positive'], ['Seems great', 'positive'], ['Much faster than the other brands', 'positive'], ['Good product was worth the money', 'positive'], ['Quality is not good', 'negative'], ['I am really impressed with the sound quality of these', 'positive'], ['Well worth the money', 'positive'], ['Great feedback and smooth function', 'positive']]\n"
     ]
    }
   ],
   "source": [
    "from operator import index\n",
    "import random\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from csv import reader\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "'''\n",
    "TRAINING PROGRAM:\n",
    "create a hashmap: key = class value = documents\n",
    "we will have 2 class\n",
    "tokenize, normalize,find vreq, unique value of class\n",
    "find prior prob P(0), P(1)\n",
    "find likelihood conditional prob for each word\n",
    "\n",
    "output the probablity to a csv file: model.csv\n",
    "'''\n",
    "\n",
    "# read csv file as a list of lists\n",
    "with open('train.csv','r') as read_obj:\n",
    "    # pass the file object to reader() to get the reader object\n",
    "    csv_reader = reader(read_obj)\n",
    "    # Pass reader object to list() to get a list of lists\n",
    "    list_of_rows = list(csv_reader)\n",
    "\n",
    "print(list_of_rows)\n",
    "#all the vocabs from csv file\n",
    "vocablist = \"\"\n",
    "pos_vocab = \"\" #positive class vocabs\n",
    "neg_vocab = \"\" #negative class vocabs\n",
    "\n",
    "pos_doc = 0 #counts total # of positive document\n",
    "neg_doc = 0 #counts total # of negative document\n",
    "\n",
    "#splitting positive and negative class vocabs and storing into seperate string\n",
    "for words in list_of_rows:\n",
    "    vocablist = vocablist + words[0] + \" \"\n",
    "    if words[1] == \"positive\":\n",
    "        pos_doc += 1\n",
    "        pos_vocab = pos_vocab + words[0] + \" \"\n",
    "    else:\n",
    "        neg_doc += 1\n",
    "        neg_vocab = neg_vocab + words[0] + \" \"\n",
    "\n",
    "#Calculate the prior probabilities for both classes using the training set\n",
    "#total # documents in csv file\n",
    "total_doc = len(list_of_rows)\n",
    "priors_prob_pos = pos_doc / total_doc\n",
    "priors_prob_neg = neg_doc / total_doc\n",
    "\n",
    "#print(priors_prob_pos)\n",
    "#print(priors_prob_neg)\n",
    "\n",
    "\n",
    "#function to tokenize the vocablist\n",
    "def vocab_tokenize(valuec):\n",
    "        normalize_corpus = valuec.lower()\n",
    "        tokenize = word_tokenize(normalize_corpus)\n",
    "        tokenize=[word.lower() for word in tokenize if word.isalpha()]\n",
    "        return tokenize\n",
    "  \n",
    "#counting frequency of all words in the corpus\n",
    "#returns dict of word:freq\n",
    "def vocab_builder(vocabs):\n",
    "        vocab = {}\n",
    "        for x in vocabs:\n",
    "            if vocab.get(x) == None:\n",
    "                vocab[x] = 1\n",
    "            else:\n",
    "                vocab[x] = vocab.get(x)+1\n",
    "        return vocab\n",
    "#all the vocabs from csv file\n",
    "vocab_token = vocab_tokenize(vocablist)\n",
    "vocab_freq = vocab_builder(vocab_token)\n",
    "total_vocab = len(vocab_freq)\n",
    "\n",
    "#vocab from pos class\n",
    "pos_class_token = vocab_tokenize(pos_vocab)\n",
    "pos_class_freq = vocab_builder(pos_class_token)\n",
    "toal_word_pos = len(pos_class_token)\n",
    "\n",
    "#vocab from neg class\n",
    "neg_class_token = vocab_tokenize(neg_vocab)\n",
    "neg_class_freq = vocab_builder(neg_class_token)\n",
    "total_word_neg = len(neg_class_token)\n",
    "\n",
    "#Calculate the conditional probability of each unique word in the training set given a class. Compute these conditional probabilities for each class. \n",
    "\n",
    "#conditional probability of positive class\n",
    "pos_cond_probs = {} #hashmap of word:cond prob of pos class\n",
    "for word in pos_class_freq:\n",
    "    pos_cond_probs[word] = (pos_class_freq[word] + 1) / (toal_word_pos + total_vocab) #using conditional probability formula and laplace smoothing of 1\n",
    "#print(f\"pos class prob: {pos_cond_probs}\")\n",
    "\n",
    "\n",
    "#conditional probability of negative class\n",
    "neg_cond_probs = {} #hashmap of word:cond prob of neg class\n",
    "for word in neg_class_freq:\n",
    "    neg_cond_probs[word] = (neg_class_freq[word]+1) / (total_word_neg + total_vocab)\n",
    "    \n",
    "#for debug\n",
    "#print(f\"negative class prob: {neg_cond_probs}\")\n",
    "#print(f\"test: {neg_class_freq['difficult']}  count(c): {total_word_neg} |V|: {total_vocab}\")\n",
    "\n",
    "\n",
    "#Output the learnt classification model (all the above probabilities) to a file named model.csv\n",
    "#opening and writing to model.csv file\n",
    "with open('model.csv','w',newline='') as model:\n",
    "    writer = csv.writer(model)\n",
    "    \n",
    "    #writing prior probablity to model.csv\n",
    "    writer.writerow(['Prior probablity'])\n",
    "    writer.writerow(['class','probablity'])\n",
    "    writer.writerow([\"negative\", priors_prob_neg])\n",
    "    writer.writerow([\"positive\", priors_prob_pos])\n",
    "    \n",
    "    writer.writerow(['word','class','probablity'])\n",
    "    #writing negative class cond probablity to model.csv\n",
    "    for word in neg_cond_probs:\n",
    "        temp_neg = [word, \"negative\", neg_cond_probs[word]]\n",
    "        writer.writerow(temp_neg)\n",
    "        \n",
    "        \n",
    "    #writing positive class cond probablity to model.csv\n",
    "    for word in pos_cond_probs:\n",
    "        temp_pos = [word, \"positive\", pos_cond_probs[word]]\n",
    "        writer.writerow(temp_pos)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos PP: 0.5806451612903226\n",
      "neg PP: 0.41935483870967744\n",
      "well\n",
      "crafted\n",
      "and\n",
      "looks\n",
      "very\n",
      "nice\n",
      "i\n",
      "love\n",
      "it\n",
      "and\n",
      "it\n",
      "looks\n",
      "great\n",
      "in\n",
      "the\n",
      "kitchen\n",
      "i\n",
      "would\n",
      "highly\n",
      "recommen\n",
      "this\n",
      "item\n",
      "these\n",
      "suck\n",
      "noisy\n",
      "pricey\n",
      "not\n",
      "worth\n",
      "the\n",
      "price\n",
      "good\n",
      "quality\n",
      "and\n",
      "print\n",
      "is\n",
      "nice\n",
      "does\n",
      "not\n",
      "do\n",
      "a\n",
      "very\n",
      "good\n",
      "job\n",
      "awesome\n",
      "bag\n",
      "[['well crafted and looks very nice', 'positive', 'positive'], ['i love it and it looks great in the kitchen', 'positive', 'positive'], ['i would highly recommen this item', 'positive', 'positive'], ['these suck', 'positive', 'negative'], ['noisy', 'negative', 'negative'], ['pricey', 'negative', 'negative'], ['not worth the price', 'positive', 'negative'], ['good quality and print is nice', 'positive', 'positive'], ['does not do a very good job', 'negative', 'negative'], ['awesome bag', 'positive', 'positive']]\n"
     ]
    }
   ],
   "source": [
    "from operator import index\n",
    "import random\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import math\n",
    "from csv import reader\n",
    "\n",
    "\"\"\"\n",
    "Step 3) Use the learnt NB classifier (Program 2)\n",
    "\n",
    "3.a) Read in the model.csv file and the test.csv files \n",
    "\n",
    "3.b) Use the classification model to predict class label for each document in the test set\n",
    "\n",
    "3.c) Output each of the test document, its predicted class label, and its actual class label to a file named test_predictions.csv\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Read in the model.csv file and the test.csv files\n",
    "with open('model.csv','r') as model_obj:\n",
    "    # pass the file object to reader() to get the reader object\n",
    "    model_reader = reader(model_obj)\n",
    "    # Pass reader object to list() to get a list of lists\n",
    "    model_list = list(model_reader)\n",
    "    \n",
    "with open('test.csv','r') as test_obj:\n",
    "    # pass the file object to reader() to get the reader object\n",
    "    test_reader = reader(test_obj)\n",
    "    # Pass reader object to list() to get a list of lists\n",
    "    test_list = list(test_reader)\n",
    "    \n",
    "#print(model_list)\n",
    "#Use the classification model to predict class label for each document in the test set\n",
    "\n",
    "#prior probablity of class\n",
    "pos_prior_prob = model_list[3][1]\n",
    "neg_prior_prob = model_list[2][1]\n",
    "print(f\"pos PP: {pos_prior_prob}\")\n",
    "print(f\"neg PP: {neg_prior_prob}\")\n",
    "\n",
    "positive_class = {} #hashmap of word:cond prob of positive class\n",
    "negative_class ={} #hashmap of word:cond prob of negative class\n",
    "\n",
    "#looping through list of model.csv to differenciate positive and negative class\n",
    "for x in range(5, len(model_list)):\n",
    "    if(model_list[x][1] == \"positive\"):\n",
    "        positive_class[model_list[x][0]] = model_list[x][2]\n",
    "    else:\n",
    "        negative_class[model_list[x][0]] = model_list[x][2]\n",
    "\n",
    "label_list = []\n",
    "for x in test_list:\n",
    "    \n",
    "    pos_prob = 0;\n",
    "    neg_prob = 0;\n",
    "    temp = x[0].lower()\n",
    "   # print(x[0])\n",
    "    for word in temp.split():\n",
    "        print(word)\n",
    "        if word in positive_class:\n",
    "            pos_prob += math.log(float(positive_class[word]))\n",
    "        if word in negative_class:\n",
    "            neg_prob += math.log(float(negative_class[word]))\n",
    "    pos_prob += math.log(float(pos_prior_prob))\n",
    "    neg_prob += math.log(float(neg_prior_prob))\n",
    "    \n",
    "    # ['test document','predicted class','actual class label'])\n",
    "    if pos_prob < neg_prob:\n",
    "        label_list.append([temp,'positive',x[1]])\n",
    "    else:\n",
    "        label_list.append([temp,'negative',x[1]])\n",
    "\n",
    "print(label_list)\n",
    "\n",
    "\n",
    "with open('test_predictions.csv','w',newline='') as predict:\n",
    "    writer = csv.writer(predict)\n",
    "\n",
    "    writer.writerow(['test document','predicted class','actual class label'])\n",
    "    #writing negative class cond probablity to model.csv\n",
    "    for word in label_list:\n",
    "        temp_row = [word[0], word[1], word[2]]\n",
    "        writer.writerow(temp_row)\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('nlpenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6801ae3e431dd180d2cc72d84ce6feb33b452596a28ade9b15354c20274f8a46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
