{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Text Classification Using Naive Bayes \n",
    "\n",
    "Step 1) Create Training set & Test set \n",
    "\n",
    "1.a) Manually create a small labeled dataset for a two-class problem (e.g. spam vs ham OR positive vs negative reviews).  Aim for 30 or more datapoints for this dataset.  Each datapoint consists of a tuple: a document and its class label.  The document can simply be a sentence or two.   \n",
    "\n",
    "1.b) Split this dataset into Training set (80%) and Test set (20%). \n",
    "\n",
    "1.c) Store the created data into two files: train.csv and test.csv (One datapoint per line)\n",
    "\n",
    "Step 2) Train a Naive Bayes classifier (Program 1)\n",
    "\n",
    "2.a) Read in training set from the train.csv file \n",
    "\n",
    "2.b) Calculate the prior probabilities for both classes using the training set\n",
    "\n",
    "2.b) Calculate the conditional probability of each unique word in the training set given a class. Compute these conditional probabilities for each class. \n",
    "\n",
    "2.c) Output the learnt classification model (all the above probabilities) to a file named model.csv\n",
    "\n",
    "Step 3) Use the learnt NB classifier (Program 2)\n",
    "\n",
    "3.a) Read in the model.csv file and the test.csv files \n",
    "\n",
    "3.b) Use the classification model to predict class label for each document in the test set\n",
    "\n",
    "3.c) Output each of the test document, its predicted class label, and its actual class label to a file named test_predictions.csv\n",
    "\n",
    "'''\n",
    "\n",
    "import random\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "train = pd.read_csv('train.csv', index_col=0)\n",
    "print(train.to_string())\n",
    "\n",
    "\n",
    "class training:\n",
    "    def print(self):\n",
    "        print(\"hellow world\")\n",
    "        \n",
    "    #reading the training data from csv file\n",
    "    \n",
    "    #2.b) Calculate the prior probabilities for both classes using the training set\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def run():\n",
    "    print(\"hello world\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Enter \\\"q\\\" to end: \")\n",
    "    print(\"Courpus: 1865-Lincoln.txt from inaugural corpus\")\n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Perfect. They do exactly what I need them to do. I will keep them for a long time', 'positive'], ['Excellent product and a much better quality than the one you get at Walmart for $50', 'positive'], ['A little pricey for what it is', 'negative'], ['sheds all over, would not buy it ever again', 'negative'], [\"service was great, can't wait to try it out!Very good quality\", 'positive'], ['bottom will not stay on. zero customer service  do not buy', 'negative'], ['Does not do a very good job', 'negative'], ['difficult to use', 'negative'], ['I am happy with my purchase', 'positive'], ['so poor on quality', 'negative'], ['it was broken and the glass is  cracked bad', 'negative'], ['Only negative is the shape of the container', 'negative'], ['Worst product ever', 'negative'], ['Works very well', 'positive'], ['Perfect! this bag is well made', 'positive'], ['heaply made, poor quality', 'negative'], ['Item as advertised, fast shipping', 'positive'], ['arrived on time', 'positive'], ['This is a must have for anyone', 'positive'], ['Awesome bag', 'positive'], ['The mask was a very poor fit', 'negative'], [\"I've really enjoyed using this\", 'positive'], ['Unfortunately, there were no batteries', 'negative'], ['These are adorable!', 'positive'], ['Seems great', 'positive'], ['Much faster than the other brands', 'positive'], ['Good product was worth the money', 'positive'], ['Quality is not good', 'negative'], ['I am really impressed with the sound quality of these', 'positive'], ['Well worth the money', 'positive'], ['Great feedback and smooth function', 'positive']]\n"
     ]
    }
   ],
   "source": [
    "from operator import index\n",
    "import random\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from csv import reader\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "'''\n",
    "TRAINING PROGRAM:\n",
    "create a hashmap: key = class value = documents\n",
    "we will have 2 class\n",
    "tokenize, normalize,find vreq, unique value of class\n",
    "find prior prob P(0), P(1)\n",
    "find likelihood conditional prob for each word\n",
    "\n",
    "output the probablity to a csv file: model.csv\n",
    "'''\n",
    "\n",
    "# read csv file as a list of lists\n",
    "with open('train.csv','r') as read_obj:\n",
    "    # pass the file object to reader() to get the reader object\n",
    "    csv_reader = reader(read_obj)\n",
    "    # Pass reader object to list() to get a list of lists\n",
    "    list_of_rows = list(csv_reader)\n",
    "\n",
    "print(list_of_rows)\n",
    "#all the vocabs from csv file\n",
    "vocablist = \"\"\n",
    "pos_vocab = \"\" #positive class vocabs\n",
    "neg_vocab = \"\" #negative class vocabs\n",
    "\n",
    "pos_doc = 0 #counts total # of positive document\n",
    "neg_doc = 0 #counts total # of negative document\n",
    "\n",
    "#splitting positive and negative class vocabs and storing into seperate string\n",
    "for words in list_of_rows:\n",
    "    vocablist = vocablist + words[0] + \" \"\n",
    "    if words[1] == \"positive\":\n",
    "        pos_doc += 1\n",
    "        pos_vocab = pos_vocab + words[0] + \" \"\n",
    "    else:\n",
    "        neg_doc += 1\n",
    "        neg_vocab = neg_vocab + words[0] + \" \"\n",
    "\n",
    "#Calculate the prior probabilities for both classes using the training set\n",
    "#total # documents in csv file\n",
    "total_doc = len(list_of_rows)\n",
    "priors_prob_pos = pos_doc / total_doc\n",
    "priors_prob_neg = neg_doc / total_doc\n",
    "\n",
    "#print(priors_prob_pos)\n",
    "#print(priors_prob_neg)\n",
    "\n",
    "\n",
    "#function to tokenize the vocablist\n",
    "def vocab_tokenize(valuec):\n",
    "        normalize_corpus = valuec.lower()\n",
    "        tokenize = word_tokenize(normalize_corpus)\n",
    "        tokenize=[word.lower() for word in tokenize if word.isalpha()]\n",
    "        return tokenize\n",
    "  \n",
    "#counting frequency of all words in the corpus\n",
    "#returns dict of word:freq\n",
    "def vocab_builder(vocabs):\n",
    "        vocab = {}\n",
    "        for x in vocabs:\n",
    "            if vocab.get(x) == None:\n",
    "                vocab[x] = 1\n",
    "            else:\n",
    "                vocab[x] = vocab.get(x)+1\n",
    "        return vocab\n",
    "#all the vocabs from csv file\n",
    "vocab_token = vocab_tokenize(vocablist)\n",
    "vocab_freq = vocab_builder(vocab_token)\n",
    "total_vocab = len(vocab_freq)\n",
    "\n",
    "#vocab from pos class\n",
    "pos_class_token = vocab_tokenize(pos_vocab)\n",
    "pos_class_freq = vocab_builder(pos_class_token)\n",
    "toal_word_pos = len(pos_class_token)\n",
    "\n",
    "#vocab from neg class\n",
    "neg_class_token = vocab_tokenize(neg_vocab)\n",
    "neg_class_freq = vocab_builder(neg_class_token)\n",
    "total_word_neg = len(neg_class_token)\n",
    "\n",
    "#Calculate the conditional probability of each unique word in the training set given a class. Compute these conditional probabilities for each class. \n",
    "\n",
    "#conditional probability of positive class\n",
    "pos_cond_probs = {} #hashmap of word:cond prob of pos class\n",
    "for word in pos_class_freq:\n",
    "    pos_cond_probs[word] = (pos_class_freq[word] + 1) / (toal_word_pos + total_vocab) #using conditional probability formula and laplace smoothing of 1\n",
    "#print(f\"pos class prob: {pos_cond_probs}\")\n",
    "\n",
    "\n",
    "#conditional probability of negative class\n",
    "neg_cond_probs = {} #hashmap of word:cond prob of neg class\n",
    "for word in neg_class_freq:\n",
    "    neg_cond_probs[word] = (neg_class_freq[word]+1) / (total_word_neg + total_vocab)\n",
    "    \n",
    "#for debug\n",
    "#print(f\"negative class prob: {neg_cond_probs}\")\n",
    "#print(f\"test: {neg_class_freq['difficult']}  count(c): {total_word_neg} |V|: {total_vocab}\")\n",
    "\n",
    "\n",
    "#Output the learnt classification model (all the above probabilities) to a file named model.csv\n",
    "#opening and writing to model.csv file\n",
    "with open('model.csv','w') as model:\n",
    "    writer = csv.writer(model)\n",
    "    \n",
    "    #writing prior probablity to model.csv\n",
    "    writer.writerow(['Prior probablity'])\n",
    "    writer.writerow(['class','probablity'])\n",
    "    writer.writerow([\"negative\", priors_prob_neg])\n",
    "    writer.writerow([\"positive\", priors_prob_pos])\n",
    "    \n",
    "    writer.writerow(['word','class','probablity'])\n",
    "    #writing negative class cond probablity to model.csv\n",
    "    for word in neg_cond_probs:\n",
    "        temp_neg = [word, \"negative\", neg_cond_probs[word]]\n",
    "        writer.writerow(temp_neg)\n",
    "        \n",
    "        \n",
    "    #writing positive class cond probablity to model.csv\n",
    "    for word in pos_cond_probs:\n",
    "        temp_pos = [word, \"positive\", pos_cond_probs[word]]\n",
    "        writer.writerow(temp_pos)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Prior probablity']\n"
     ]
    }
   ],
   "source": [
    "from operator import index\n",
    "import random\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from csv import reader\n",
    "\n",
    "\"\"\"\n",
    "Step 3) Use the learnt NB classifier (Program 2)\n",
    "\n",
    "3.a) Read in the model.csv file and the test.csv files \n",
    "\n",
    "3.b) Use the classification model to predict class label for each document in the test set\n",
    "\n",
    "3.c) Output each of the test document, its predicted class label, and its actual class label to a file named test_predictions.csv\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Read in the model.csv file and the test.csv files\n",
    "with open('model.csv','r') as model_obj:\n",
    "    # pass the file object to reader() to get the reader object\n",
    "    model_reader = reader(model_obj)\n",
    "    # Pass reader object to list() to get a list of lists\n",
    "    model_list = list(model_reader)\n",
    "    \n",
    "with open('test.csv','r') as test_obj:\n",
    "    # pass the file object to reader() to get the reader object\n",
    "    test_reader = reader(test_obj)\n",
    "    # Pass reader object to list() to get a list of lists\n",
    "    test_list = list(test_reader)\n",
    "    \n",
    "print(model_list[0])\n",
    "#print(test_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('nlpenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6801ae3e431dd180d2cc72d84ce6feb33b452596a28ade9b15354c20274f8a46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
