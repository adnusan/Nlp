{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import index\n",
    "import random\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from csv import reader\n",
    "from nltk.tokenize import word_tokenize\n",
    "import csv\n",
    "'''\n",
    "sorry, didn't have enough time to organize into classes and functions :(\n",
    "    \n",
    "Step 2) Train a Naive Bayes classifier (Program 1)\n",
    "\n",
    "2.a) Read in training set from the train.csv file \n",
    "\n",
    "2.b) Calculate the prior probabilities for both classes using the training set\n",
    "\n",
    "2.b) Calculate the conditional probability of each unique word in the training set given a class. Compute these conditional probabilities for each class. \n",
    "\n",
    "2.c) Output the learnt classification model (all the above probabilities) to a file named model.csv    \n",
    "\n",
    "\n",
    "HAVE TIME TO COMMENT THIS PART\n",
    "TRAINING PROGRAM:\n",
    "create a hashmap: key = class value = documents\n",
    "we will have 2 class\n",
    "tokenize, normalize,find vreq, unique value of class\n",
    "find prior prob P(0), P(1)\n",
    "find likelihood conditional prob for each word\n",
    "\n",
    "output the probablity to a csv file: model.csv\n",
    "'''\n",
    "#pos = positive class \n",
    "#neg = negative class\n",
    "\n",
    "\n",
    "# read csv file as a list of lists\n",
    "with open('train.csv','r') as read_obj:\n",
    "    # pass the file object to reader() to get the reader object\n",
    "    csv_reader = reader(read_obj)\n",
    "    # Pass reader object to list() to get a list of lists\n",
    "    list_of_rows = list(csv_reader)\n",
    "\n",
    "#print(list_of_rows)\n",
    "#all the vocabs from csv file\n",
    "vocablist = \"\"\n",
    "pos_vocab = \"\" #positive class vocabs\n",
    "neg_vocab = \"\" #negative class vocabs\n",
    "\n",
    "pos_doc = 0 #counts total # of positive document\n",
    "neg_doc = 0 #counts total # of negative document\n",
    "\n",
    "#splitting positive and negative class vocabs and storing into seperate string\n",
    "for words in list_of_rows:\n",
    "    vocablist = vocablist + words[0] + \" \"\n",
    "    if words[1] == \"positive\":\n",
    "        pos_doc += 1\n",
    "        pos_vocab = pos_vocab + words[0] + \" \"\n",
    "    else:\n",
    "        neg_doc += 1\n",
    "        neg_vocab = neg_vocab + words[0] + \" \"\n",
    "\n",
    "#Calculate the prior probabilities for both classes using the training set\n",
    "#total # documents in csv file\n",
    "total_doc = len(list_of_rows)\n",
    "priors_prob_pos = pos_doc / total_doc\n",
    "priors_prob_neg = neg_doc / total_doc\n",
    "\n",
    "#print(priors_prob_pos)\n",
    "#print(priors_prob_neg)\n",
    "\n",
    "\n",
    "#function to tokenize and normalize the vocablist\n",
    "def vocab_tokenize(valuec):\n",
    "        normalize_corpus = valuec.lower()\n",
    "        tokenize = word_tokenize(normalize_corpus)\n",
    "        tokenize=[word.lower() for word in tokenize if word.isalpha()]\n",
    "        return tokenize\n",
    "  \n",
    "#counting frequency of all words in the corpus\n",
    "#returns dict of word:freq\n",
    "def vocab_builder(vocabs):\n",
    "        vocab = {}\n",
    "        for x in vocabs:\n",
    "            if vocab.get(x) == None:\n",
    "                vocab[x] = 1\n",
    "            else:\n",
    "                vocab[x] = vocab.get(x)+1\n",
    "        return vocab\n",
    "    \n",
    "#all the vocabs from csv file\n",
    "vocab_token = vocab_tokenize(vocablist)\n",
    "vocab_freq = vocab_builder(vocab_token)\n",
    "total_vocab = len(vocab_freq)\n",
    "\n",
    "#vocab from positive class label\n",
    "pos_class_token = vocab_tokenize(pos_vocab)\n",
    "pos_class_freq = vocab_builder(pos_class_token)\n",
    "toal_word_pos = len(pos_class_token)\n",
    "\n",
    "#vocab from negative class label\n",
    "neg_class_token = vocab_tokenize(neg_vocab)\n",
    "neg_class_freq = vocab_builder(neg_class_token)\n",
    "total_word_neg = len(neg_class_token)\n",
    "\n",
    "#Calculate the conditional probability of each unique word in the training set given a class. Compute these conditional probabilities for each class. \n",
    "\n",
    "#conditional probability of positive class\n",
    "pos_cond_probs = {} #hashmap of word:cond prob of pos class\n",
    "for word in pos_class_freq:\n",
    "    pos_cond_probs[word] = (pos_class_freq[word] + 1) / (toal_word_pos + total_vocab) #using conditional probability formula and laplace smoothing of 1\n",
    "#print(f\"pos class prob: {pos_cond_probs}\")\n",
    "\n",
    "\n",
    "#conditional probability of negative class\n",
    "neg_cond_probs = {} #hashmap of word:cond prob of neg class\n",
    "for word in neg_class_freq:\n",
    "    neg_cond_probs[word] = (neg_class_freq[word]+1) / (total_word_neg + total_vocab)\n",
    "    \n",
    "#for debug\n",
    "#print(f\"negative class prob: {neg_cond_probs}\")\n",
    "#print(f\"test: {neg_class_freq['difficult']}  count(c): {total_word_neg} |V|: {total_vocab}\")\n",
    "\n",
    "\n",
    "#Output the learnt classification model (all the above probabilities) to a file named model.csv\n",
    "#opening and writing to model.csv file\n",
    "with open('model.csv','w',newline='') as model:\n",
    "    writer = csv.writer(model)\n",
    "    \n",
    "    #writing prior probablity to model.csv\n",
    "    writer.writerow(['Prior probablity'])\n",
    "    writer.writerow(['class','probablity'])\n",
    "    writer.writerow([\"negative\", priors_prob_neg])\n",
    "    writer.writerow([\"positive\", priors_prob_pos])\n",
    "    \n",
    "    #writing header labels\n",
    "    writer.writerow(['word','class','probablity'])\n",
    "    \n",
    "    #writing negative class cond probablity to model.csv\n",
    "    for word in neg_cond_probs:\n",
    "        temp_neg = [word, \"negative\", neg_cond_probs[word]]\n",
    "        writer.writerow(temp_neg)\n",
    "        \n",
    "        \n",
    "    #writing positive class cond probablity to model.csv\n",
    "    for word in pos_cond_probs:\n",
    "        temp_pos = [word, \"positive\", pos_cond_probs[word]]\n",
    "        writer.writerow(temp_pos)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import index\n",
    "import random\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import math\n",
    "import csv\n",
    "from csv import reader\n",
    "\n",
    "\"\"\"\n",
    "sorry about messy code, couldn't \n",
    "Step 3) Use the learnt NB classifier (Program 2)\n",
    "\n",
    "3.a) Read in the model.csv file and the test.csv files \n",
    "\n",
    "3.b) Use the classification model to predict class label for each document in the test set\n",
    "\n",
    "3.c) Output each of the test document, its predicted class label, and its actual class label to a file named test_predictions.csv\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Read in the model.csv file and the test.csv files\n",
    "#reading test and model file and storing it as list\n",
    "with open('model.csv','r') as model_obj:\n",
    "    # pass the file object to reader() to get the reader object\n",
    "    model_reader = reader(model_obj)\n",
    "    # Pass reader object to list() to get a list of lists\n",
    "    model_list = list(model_reader)\n",
    "    \n",
    "with open('test.csv','r') as test_obj:\n",
    "    # pass the file object to reader() to get the reader object\n",
    "    test_reader = reader(test_obj)\n",
    "    # Pass reader object to list() to get a list of lists\n",
    "    test_list = list(test_reader)\n",
    "    \n",
    "\n",
    "#Use the classification model to predict class label for each document in the test set\n",
    "\n",
    "#prior probablity of each class\n",
    "pos_prior_prob = model_list[3][1]\n",
    "neg_prior_prob = model_list[2][1]\n",
    "#print(f\"pos PP: {pos_prior_prob}\")\n",
    "#print(f\"neg PP: {neg_prior_prob}\")\n",
    "\n",
    "positive_class = {} #hashmap of word:cond prob of positive class\n",
    "negative_class ={} #hashmap of word:cond prob of negative class\n",
    "\n",
    "#looping through list of model.csv to differenciate positive and negative class\n",
    "for x in range(5, len(model_list)):\n",
    "    if(model_list[x][1] == \"positive\"):\n",
    "        positive_class[model_list[x][0]] = model_list[x][2]\n",
    "    else:\n",
    "        negative_class[model_list[x][0]] = model_list[x][2]\n",
    "\n",
    "label_list = [] #holds list of test and predicted labels\n",
    "\n",
    "for x in test_list: #looping from each document of test.csv\n",
    "    pos_prob = 0;\n",
    "    neg_prob = 0;\n",
    "    temp = x[0].lower()\n",
    "   # print(x[0])\n",
    "    for word in temp.split(): #looping through each word of document of test.csv\n",
    "        #print(word)\n",
    "        #checking if word is in our label class\n",
    "        if word in positive_class: \n",
    "            pos_prob += math.log(float(positive_class[word])) #gets word probablity from positive class and calculate. using  log to avoid smaller numbers\n",
    "        if word in negative_class:\n",
    "            neg_prob += math.log(float(negative_class[word])) #gets word probablity from negative class and calculate. using  log to avoid smaller numbers\n",
    "    pos_prob += math.log(float(pos_prior_prob)) #adding positive class prior probabilities ; part of formula\n",
    "    neg_prob += math.log(float(neg_prior_prob)) #adding negative class prior probabilities ; part of formula\n",
    "    \n",
    "    # ['test document','predicted class','actual class label']) : example format to store in file\n",
    "    #comparing the probabilities of positve vs negative, since we are using log, numbers are flipped so smaller number is higher prob\n",
    "    if pos_prob < neg_prob:\n",
    "        label_list.append([temp,'positive',x[1]])\n",
    "    else:\n",
    "        label_list.append([temp,'negative',x[1]])\n",
    "\n",
    "#print(label_list)\n",
    "\n",
    "#Output each of the test document, its predicted class label, and its actual class label to a file named test_predictions.csv\n",
    "with open('test_predictions.csv','w',newline='') as predict:\n",
    "    writer = csv.writer(predict)\n",
    "    #writing to test_preditcion file\n",
    "    writer.writerow(['test document','predicted class','actual class label'])\n",
    "    for word in label_list:\n",
    "        temp_row = [word[0], word[1], word[2]]\n",
    "        writer.writerow(temp_row)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('nlpenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6801ae3e431dd180d2cc72d84ce6feb33b452596a28ade9b15354c20274f8a46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
