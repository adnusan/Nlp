{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package inaugural to\n",
      "[nltk_data]     /Users/nusanrana/nltk_data...\n",
      "[nltk_data]   Package inaugural is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter \"1\" to end: \n",
      "Courpus: 1865-Lincoln.txt from inaugural corpus\n",
      "Total unique words:  345\n",
      "Toal # word in corpus:  785 \n",
      "\n",
      "Enter word: jfdsf\n",
      "jfdsf is not a complete word in corpus!!!\n",
      "The closest 5 words are: \n",
      "just  probablity 0.0025477707006369425\n",
      "judge  probablity 0.0012738853503184713\n",
      "this  probablity 0.008917197452229299\n",
      "of  probablity 0.02802547770700637\n",
      "is  probablity 0.007643312101910828\n",
      "\n",
      "\n",
      "Enter word: test\n",
      "test is not a complete word in corpus!!!\n",
      "The closest 5 words are: \n",
      "less  probablity 0.0025477707006369425\n",
      "that  probablity 0.015286624203821656\n",
      "trust  probablity 0.0012738853503184713\n",
      "let  probablity 0.005095541401273885\n",
      "these  probablity 0.0012738853503184713\n",
      "\n",
      "\n",
      "Enter word: fellow\n",
      "fellow  is a complete and correct word as per corpus inaugural, and its probability is  0.0012738853503184713\n",
      "Frequency of  fellow  is  1\n",
      "Enter word: the\n",
      "the  is a complete and correct word as per corpus inaugural, and its probability is  0.07388535031847134\n",
      "Frequency of  the  is  58\n",
      "Enter word: 1\n",
      "Exiting program.......\n"
     ]
    }
   ],
   "source": [
    "\"\"\"HA #3\n",
    "Simple Word Autocomplete / Autocorrect and Word Probability\n",
    "\n",
    "Input argument: A string of characters, XYZ (it doesn't have to be a complete word)\n",
    "\n",
    "Output: \n",
    "\n",
    "If the input string exists in your program's vocabulary then your program should output \"XYZ is a complete and correct word in English.\"\n",
    "\n",
    "If the input string doesn't exist in your program's vocabulary then your program should output the 5 closest words to it as measured by Levenshtein distance, and their probability.\n",
    "\n",
    "Steps to follow:\n",
    "\n",
    "1) Build a vocabulary (set of all unique words) using any English corpus from nltk. This is your program's vocabulary.  (Choose a small corpus so that the vocabulary isn't too big.  This will help with step 4.b.i below.)\n",
    "\n",
    "2) Find the number of occurrences (frequency) of each word in the vocabulary.  Also, find the total number of words in the chosen corpus (N).\n",
    "\n",
    "3) Find the relative frequency of each word W where relative frequency of W = frequency_of_W / N. This relative frequency is the probability (likelihood) of each word in the corpus.  \n",
    "\n",
    "4) For every input string XYZ:\n",
    "\n",
    "4.a) If the input string XYZ exists in your vocabulary, return \"XYZ is a complete and correct word as per corpus ___, and its probability is __\"\n",
    "\n",
    "4.b) If the input string doesn't exist in your vocabulary, perform the below steps:\n",
    "\n",
    "4.b.i) Calculate the similarity between each word in the vocabulary and the input string using Levenshtein distance. (Use any open-source python library for calculating Levenshtein distance.) \n",
    "\n",
    "4.b.ii) Output the closest top 5 words as per Levenshtein distance to the input string. Also, output the probability for each of the 5 words.\n",
    "\n",
    "Submit to ilearn\n",
    "1. Your program or python notebook.\n",
    "2. Log of output showing examples of the two different user input scenarios (4.a & 4.b).\"\"\"\n",
    "\n",
    "import random\n",
    "import re\n",
    "from turtle import distance\n",
    "import nltk\n",
    "nltk.download('inaugural')\n",
    "from nltk.corpus import inaugural\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "class hw:\n",
    "\n",
    "   #function to normalize and tokenize corpus\n",
    "   #takes nltk corpus as param, returns list of words\n",
    "   def corpus_tokenize(valuec):\n",
    "      corpus = ' '.join(valuec)\n",
    "      normalize_corpus = corpus.lower()\n",
    "      tokenize = word_tokenize(normalize_corpus)\n",
    "      return tokenize\n",
    "\n",
    "\n",
    "   #function to build vocab list\n",
    "   # this function takes list of words and put them in hash map\n",
    "   # key = words, value = frequency of word\n",
    "   #returns dict of words : frequency\n",
    "   def vocab_builder(tokenize_vocab):\n",
    "      vocab = {}\n",
    "      for x in tokenize_vocab:\n",
    "         if vocab.get(x) == None:\n",
    "            vocab[x] = 1\n",
    "         else:\n",
    "            vocab[x] = vocab.get(x)+1\n",
    "      #print(vocab)\n",
    "      return vocab\n",
    "   \n",
    "\n",
    "#function to calculate probablity of words\n",
    "def demo():\n",
    "   inaugural_corpus = inaugural.words('1865-Lincoln.txt') #using 1865 inaugural speech as corpus\n",
    "   courpus_length = len(inaugural_corpus) #total words in corpus\n",
    "   testing = hw #create object of class hw\n",
    "   tokened_words = testing.corpus_tokenize(inaugural_corpus) #getting tokenized and mormalized list of words from corpus\n",
    "   vocabulary = testing.vocab_builder(tokened_words) #our vocabulary: making a dist that has word as key and frequency as value \n",
    "   unique_vocab = len(vocabulary) #getting total unique words in corpus\n",
    "   #print(vocabulary)\n",
    "   print(\"Total unique words: \",unique_vocab)\n",
    "   print(\"Toal # word in corpus: \", courpus_length,\"\\n\")\n",
    "   \n",
    "   #asking user for input until they enter quit\n",
    "   user_input = input(\"Enter word: \")\n",
    "   word_frequency = 0 #var to hold frequency of word to calculate probablity\n",
    "   word = user_input.lower()\n",
    "   distance_words = {} #hold words and edit distance between user input and words in vocab\n",
    "   sorted_distance = {} #holds sorted word : edit distance\n",
    "   while word != '1':\n",
    "      #checking is user input is in our vocabulary\n",
    "      #if word not in vocab, find edit distance and print top 5 with probablity\n",
    "      counter = 0\n",
    "      if word not in vocabulary:\n",
    "            for x in vocabulary: \n",
    "               distance = nltk.edit_distance(word,x)\n",
    "               #print(\"word\", word, \" x:\", x)\n",
    "               distance_words[x] = distance\n",
    "               counter= counter +1\n",
    "            sorted_distance = dict(sorted(distance_words.items(), key=lambda item: item[1]))\n",
    "            print(word, \"is not a complete word in corpus!!!\")\n",
    "            print(\"The closest 5 words are: \")\n",
    "            \n",
    "            #calculating probablity of top 5 words\n",
    "            for y in range(5):\n",
    "               temp_word = list(sorted_distance)[y]\n",
    "               print(temp_word, \" probablity\", vocabulary[temp_word]/courpus_length)\n",
    "            print(\"\\n\")\n",
    "               \n",
    "      #if word is in vocab, print probablity and word frequency\n",
    "      elif word in vocabulary:\n",
    "         word_frequency = vocabulary[word]\n",
    "         print (word, \" is a complete and correct word as per corpus inaugural, and its probability is \", word_frequency/courpus_length)\n",
    "         print(\"Frequency of \", word, \" is \",word_frequency,\"\\n\")\n",
    "         \n",
    "      user_input = input(\"Enter word: \")\n",
    "      word = user_input.lower()\n",
    "      \n",
    "   print(\"Exiting program.......\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   print(\"Enter \\\"1\\\" to end: \")\n",
    "   print(\"Courpus: 1865-Lincoln.txt from inaugural corpus\")\n",
    "   demo() #calling demo function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "6801ae3e431dd180d2cc72d84ce6feb33b452596a28ade9b15354c20274f8a46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
