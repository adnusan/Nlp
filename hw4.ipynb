{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package inaugural to\n",
      "[nltk_data]     /Users/nusanrana/nltk_data...\n",
      "[nltk_data]   Package inaugural is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter \"q\" to end: \n",
      "Courpus: 1865-Lincoln.txt from inaugural corpus\n",
      "Total words in corpus: 785\n",
      "Unique vocab #:  335\n",
      "Total bigrams:  704\n",
      "Unique bigram #:  648\n",
      "\n",
      "\n",
      "Exiting Program....\n"
     ]
    }
   ],
   "source": [
    "#Author: @Nusan Rana\n",
    "#Student ID: 918392558\n",
    "from audioop import reverse\n",
    "from queue import PriorityQueue\n",
    "import random\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('inaugural')\n",
    "from nltk.corpus import inaugural\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import bigrams\n",
    "\n",
    "class bigram:\n",
    "\n",
    "    #function to normalize and tokenize corpus\n",
    "    #deletes all the punctuations\n",
    "    #takes nltk corpus as param, returns list of words\n",
    "    def corpus_tokenize(valuec):\n",
    "        corpus = ' '.join(valuec)\n",
    "        normalize_corpus = corpus.lower()\n",
    "        tokenize = word_tokenize(normalize_corpus)\n",
    "        tokenize=[word.lower() for word in tokenize if word.isalpha()]\n",
    "\n",
    "        return tokenize\n",
    "  \n",
    "    #counting frequency of all words in the corpus\n",
    "    #returns dict of word:freq\n",
    "    def vocab_builder(corpus):\n",
    "        vocab = {}\n",
    "        for x in corpus:\n",
    "            if vocab.get(x) == None:\n",
    "                vocab[x] = 1\n",
    "            else:\n",
    "                vocab[x] = vocab.get(x)+1\n",
    "        #print(vocab)\n",
    "        \n",
    "        return vocab\n",
    "    \n",
    "    \n",
    "    #finding frequency of each bigram\n",
    "    #takes list of bigram as param, returns dict of bigram as key and frequency as value\n",
    "    def bigram_freq(bigrams):\n",
    "        bigram_freq  = {}\n",
    "        for x in bigrams:\n",
    "            if bigram_freq.get(x) == None:\n",
    "                    bigram_freq[x] = 1\n",
    "            else:\n",
    "                    bigram_freq[x] = bigram_freq.get(x)+1\n",
    "            #print(vocab)\n",
    "        return bigram_freq\n",
    "    \n",
    "    #1B) Compute probability of each bigram using MLE (count(w1 w2)/count(w1)) \n",
    "    def bigram_prob(bigram_freq, vocab):\n",
    "        bigram_prob = {}\n",
    "        for x in bigram_freq:\n",
    "            bigram_prob[x] = bigram_freq.get(x)/vocab.get(x[0]) #calculating probablity of each bigram and storing in dicta as corresponding value\n",
    "            \n",
    "        return bigram_prob\n",
    "    \n",
    "    \n",
    "    #2A) Get an input word from user, inpW.\n",
    "    #takes dict of bigram and prob, unique vocab as param\n",
    "    #prints all next word and prob in descending order\n",
    "    def user_input(bigram_probablity, vocab):\n",
    "        inpW = input(\"Enter a word: \")\n",
    "        user_word = inpW.lower() #normalizing user input\n",
    "        next_word = {} #hashmap to store next word and prob\n",
    "        while user_word != 'q': #loop until user wants to exit\n",
    "            if user_word in vocab: #checking is user input is vaid\n",
    "                for x in bigram_probablity:\n",
    "                    if user_word == x[0]:\n",
    "                        next_word[x[1]] = bigram_probablity.get(x) #inserting word as keu, prob as value\n",
    "                \n",
    "                #sorting next word by probablity\n",
    "                sorted_distance = dict(sorted(next_word.items(), key=lambda item: item[1],reverse=True)) #sorting words by probablity\n",
    "                \n",
    "                #printing all possible words and prob\n",
    "                print(f\"\\nPossible next words and probablity after \\\"{inpW}\\\": \")\n",
    "                for y in sorted_distance: #looping through possible words\n",
    "                    print(f\"Word: {y}     Probablity: {sorted_distance.get(y)}\")\n",
    "                    \n",
    "                sorted_distance.clear() #clearing dict for nextinput\n",
    "                next_word.clear() #clearing dict for next input\n",
    "                inpW = input(\"Enter a word: \")\n",
    "                user_word = inpW.lower()\n",
    "            else: #if user input is not in our vocab\n",
    "                print(f\"\\n\\\"{inpW}\\\" is not in corpus..\")\n",
    "                inpW = input(\"Enter a word: \")\n",
    "                user_word = inpW.lower()\n",
    "        print(\"Exiting Program....\")    \n",
    "    \n",
    "def run():  \n",
    "    #creating bigram class instance\n",
    "    bigram_obj = bigram\n",
    "    \n",
    "    inaugural_corpus = inaugural.words('1865-Lincoln.txt') #using inaugural corpus\n",
    "    tokened_corpus = bigram_obj.corpus_tokenize(inaugural_corpus) #tokenizing corpus\n",
    "    vocab_freq =  bigram_obj.vocab_builder(tokened_corpus)     #creating a dict that holds word and it's frequency\n",
    "    \n",
    "    #finding all the bigrams using bigrams function\n",
    "    bigram_list = list((bigrams(tokened_corpus))) #list of all the bigrams in the corpus_tokenize\n",
    "\n",
    "    #creating a dict and calling function to find it's frequency\n",
    "    bigram_freq =  bigram_obj.bigram_freq(bigram_list)\n",
    "    \n",
    "    #dict of bigram and probablity, calling function to find it's probablity\n",
    "    bigram_prob = bigram_obj.bigram_prob(bigram_freq, vocab_freq)\n",
    "    \n",
    "    #prompts for user\n",
    "    print(\"Total words in corpus:\", len(inaugural_corpus))\n",
    "    print(\"Unique vocab #: \",len(vocab_freq))\n",
    "    print(\"Total bigrams: \", len(bigram_list))\n",
    "    print(\"Unique bigram #: \",len(bigram_freq))\n",
    "    print(\"\\n\")\n",
    "    #calling function to get user input\n",
    "    user_word = bigram_obj.user_input(bigram_prob, vocab_freq)\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Enter \\\"q\\\" to end: \")\n",
    "    print(\"Courpus: 1865-Lincoln.txt from inaugural corpus\")\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('nlpenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e36713bed272a9d114316a294fb6c1a826f423acbc1d9527c9480bc3366607df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
